# Explanation of files (also, progress tracking)

1. Test simple models
    - simple_NaiveBayes.ipynb 
        - Naive bayes model with news title tokens. 
        - Too good accuracy. Potential biased feature(s) in this dataset is suspected.
    - simple_LSTM.ipynb
        - LSTM model with pretrained embeddings of title tokens. 
        - Some words might not have corresponding pretrained embeddings
        - Better accuracy with trainable embedding layer.
        - Sign of overfit.
    - simple_FNN.ipynb
        - Feedforward NN model with averaged pretrained embedding vectors of title. 
        - Some words might not have corresponding pretrained embeddings
        - Better accuracy with trainable embedding layer.
        - Sign of overfit.

2. EDA of raw data
    - Findings from selected examples
        - Real news title is **shorter** than fake news.
        - Real news have **informative and concise** tone.
        - Fake news sounds **gossip, emotilnal, redundunt,** and awkward in **grammar structure**
        - Fake news contains **click bait** (e.g. "DETAILS", "VIDEO", full name of a person, exclamation).
        - **First names** occurs in title frequently in fake news, which is not preferred in real news to be concise. 
        - Fake news has irregular text format:
            - Extra **upper cases**, probably to catch attention.
            - Text is **noisier** with various special characters and links.
        - Some fake news title has a **slang** word, where its partial characters are replaced with special characters (e.g. "sh\*t", "a@@")
        - Fake news quote social media or website much more frequently.
        - Fake news with empty/short titles have web addresses as their titles. It looks like an impropper cleaning of web scrapping data.
        
    - Findings from statistics
        - **"Video"** is one of the most frequent title words for fake news
        - **Various special charactors** in title
        - **Exclamation** marks (!, ?) are frequently used, which make fake news sounds **emotional**.
        - A lot of **"@"** in text, probably they spread fake news by **quoting social media**, like a **rumor** is generated by quoting other person.
        - **Title words are surprisingly polarized**, i.e. 89% of words are not overlapping, which explains **why our simple models perform with surprisingly high accuracy**. It turned out that **classification power** mostly comes from **different capitalization rules between real and fake news**. Fake news have too much capitalization, probably to catch attention. We should check this point again after preprocess text.
        - Some **international** issues words appear only in real news. However, you can't tell if that's because fake news care more about **domestic politics** or this dataset is **biased**.

    
    - Note for preprocessings
        - Real news starts with source, **"Location (Reuters)"**. This part should be removed in order not to introduce bias when genalize this model out of Reuter news.
        - Unifying or distinguishing words with **Upper** case and **abbreviation** would be tricky for fake news.
            - "US", "us", "U.S.", "U.S", "U.S.A."
            - "IS" and "is"
            - "PM", "P.M.", and "p.m."
        - Some capital letter headache (e.g. distinguish "House" and "house") can be solved by using **bigram**. Bigram can select some of proper nouns combined by two common nouns, such as **White House, North Korea**. 
        - Consider taging or removing **click bait words** (e.g. "[Watch]", "[Image]", "[Details]) to avoid bias
        - Tag or remove words with **"\*"** charactor (probably a slang, which is not used in real news)
        
3. Text preprocessing and EDA
    - organize_text_data.ipynb
        - Cleaned and wrangled text data
        - Tag POS and lemmatize
        - Prepared for both Naybe Bayes and Word Embedding models
        
4. Make and test a manual model
    - sample_Manual.ipynb
        - To verify machine learning models are better than manual data selection
        - Utilize findings from EDA for fake news detection
            - Long title size
            - Too many special characters
            - Contains click bait
            - Contains first name
            - Contains slang
        - Overall bad accuracy (50%, not better than random selection), but good precision.
    
5. Test all machine learning models
    - models_evaluation.ipynb
        - Added variations to simple models
        - Ran all models with various organized data
        - Saved test results for error analysis


6. Combine models for better performance
    - final_model.ipynb
        - Compare results and correlation of each model
        - Build a final model with vote
        - Final model showed 99% accuracy/precision/recall, better than any of single simple model
        

7. Etc
    - freq_utils.py: frequently used function
    - data: contains all data files