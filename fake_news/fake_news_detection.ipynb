{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3171b473",
   "metadata": {},
   "source": [
    "# Set constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "996d7310",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 20 # max sentence size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075d1950",
   "metadata": {},
   "source": [
    "# Load libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96ecafbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from freq_utils import *\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, precision_score, recall_score, f1_score\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "pd.options.display.max_colwidth = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf88ab3",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb39b80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_csv('data/TrueOrganized.csv')\n",
    "df1 = pd.read_csv('data/FakeOrganized.csv')\n",
    "df0['label'] = 0\n",
    "df1['label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69af2369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>pos</th>\n",
       "      <th>cleaned_words</th>\n",
       "      <th>cleaned_pos</th>\n",
       "      <th>minimal_words</th>\n",
       "      <th>org_title</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13007</th>\n",
       "      <td>13007</td>\n",
       "      <td>Greek top court to decide Dec  13 on Russia cyber suspect extradition</td>\n",
       "      <td>[('Greek', 'JJ'), ('top', 'JJ'), ('court', 'NN'), ('to', 'TO'), ('decide', 'VB'), ('Dec', 'NNP'), ('13', 'CD'), ('on', 'IN'), ('Russia', 'NNP'), ('cyber', 'NN'), ('suspect', 'NN'), ('extradition',...</td>\n",
       "      <td>greek top court to decide dec 13 on russia cyber suspect extradition</td>\n",
       "      <td>JJ JJ NN TO VB NNP CD IN NNP NN NN NN</td>\n",
       "      <td>greek top court decide dec russia cyber suspect extradition</td>\n",
       "      <td>Greek top court to decide Dec. 13 on Russia cyber suspect extradition</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4245</th>\n",
       "      <td>4245</td>\n",
       "      <td>Trump administration issues final rule on stricter Obamacare enrollment</td>\n",
       "      <td>[('Trump', 'NNP'), ('administration', 'NN'), ('issues', 'NNS'), ('final', 'JJ'), ('rule', 'NN'), ('on', 'IN'), ('stricter', 'NN'), ('Obamacare', 'NNP'), ('enrollment', 'NN')]</td>\n",
       "      <td>trump administration issues final rule on stricter obamacare enrollment</td>\n",
       "      <td>NNP NN NNS JJ NN IN NN NNP NN</td>\n",
       "      <td>trump administration issue final rule stricter obamacare enrollment</td>\n",
       "      <td>Trump administration issues final rule on stricter Obamacare enrollment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  \\\n",
       "13007       13007   \n",
       "4245         4245   \n",
       "\n",
       "                                                                         title  \\\n",
       "13007    Greek top court to decide Dec  13 on Russia cyber suspect extradition   \n",
       "4245   Trump administration issues final rule on stricter Obamacare enrollment   \n",
       "\n",
       "                                                                                                                                                                                                           pos  \\\n",
       "13007  [('Greek', 'JJ'), ('top', 'JJ'), ('court', 'NN'), ('to', 'TO'), ('decide', 'VB'), ('Dec', 'NNP'), ('13', 'CD'), ('on', 'IN'), ('Russia', 'NNP'), ('cyber', 'NN'), ('suspect', 'NN'), ('extradition',...   \n",
       "4245                            [('Trump', 'NNP'), ('administration', 'NN'), ('issues', 'NNS'), ('final', 'JJ'), ('rule', 'NN'), ('on', 'IN'), ('stricter', 'NN'), ('Obamacare', 'NNP'), ('enrollment', 'NN')]   \n",
       "\n",
       "                                                                 cleaned_words  \\\n",
       "13007     greek top court to decide dec 13 on russia cyber suspect extradition   \n",
       "4245   trump administration issues final rule on stricter obamacare enrollment   \n",
       "\n",
       "                                 cleaned_pos  \\\n",
       "13007  JJ JJ NN TO VB NNP CD IN NNP NN NN NN   \n",
       "4245           NNP NN NNS JJ NN IN NN NNP NN   \n",
       "\n",
       "                                                             minimal_words  \\\n",
       "13007          greek top court decide dec russia cyber suspect extradition   \n",
       "4245   trump administration issue final rule stricter obamacare enrollment   \n",
       "\n",
       "                                                                     org_title  \\\n",
       "13007    Greek top court to decide Dec. 13 on Russia cyber suspect extradition   \n",
       "4245   Trump administration issues final rule on stricter Obamacare enrollment   \n",
       "\n",
       "       label  \n",
       "13007      0  \n",
       "4245       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df0.sample(2)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa78c2fa",
   "metadata": {},
   "source": [
    "# Make dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a586e5",
   "metadata": {},
   "source": [
    "### Pretrained word embeddings\n",
    "- Word to index\n",
    "- Word to vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf9ccfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index, index_to_word, word_to_vector = get_pretrained_embedding()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e771f3",
   "metadata": {},
   "source": [
    "### PoS tag encodings\n",
    "- PoS word to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97665ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df0.cleaned_pos, df1.cleaned_pos])\n",
    "\n",
    "pos_set = set()\n",
    "for x in list(df.str.lower().str.split()):\n",
    "    pos_set.update(x)\n",
    "\n",
    "pos_list = list(pos_set)\n",
    "pos_to_index = { pos_list[i]: i for i in range(len(pos_list)) }\n",
    "\n",
    "print(pos_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25de8845",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pos_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316ee6bb",
   "metadata": {},
   "source": [
    "# Train/dev/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da35a492",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev, test = train_dev_test_split([df0, df1], m=1000, class_column='label', \n",
    "                                    class_balance=True, r_dev=0.2, r_test=0.2, rand_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8b7d5e",
   "metadata": {},
   "source": [
    "# Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3da35d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_NB(train,dev,test,Xname='title',Yname='label'):\n",
    "    \n",
    "    train = pd.concat([train,dev])\n",
    "    \n",
    "    X_train = train[Xname].tolist()\n",
    "    Y_train = train[Yname].tolist()\n",
    "\n",
    "    X_test = test[Xname].tolist()\n",
    "    Y_test = test[Yname].tolist()\n",
    "    \n",
    "    counter = CountVectorizer()\n",
    "\n",
    "    counter.fit(X_train+X_test)\n",
    "\n",
    "    train_counts = counter.transform(X_train)\n",
    "    test_counts = counter.transform(X_test)\n",
    "\n",
    "    #print(counter.vocabulary_)\n",
    "\n",
    "    classifier = MultinomialNB()\n",
    "    classifier.fit(train_counts,Y_train)\n",
    "    \n",
    "    predict = classifier.predict(test_counts)\n",
    "    \n",
    "    proba = classifier.predict_proba(test_counts)\n",
    "    \n",
    "    model_name = 'Naive Bayse - '+Xname\n",
    "    \n",
    "    \n",
    "    return model_name, predict, Y_test, proba, classifier, counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d21c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_FNN(input_shape, word_to_index, word_to_vector, n_class=2, trainable=False):\n",
    "    '''\n",
    "    input_shape: (max_len,)\n",
    "    word_to_index: word to index dictionary\n",
    "    word_to_vector: word to embedding vector dictionary\n",
    "\n",
    "    return model\n",
    "\n",
    "    then\n",
    "    X: Indices of a sentence (m, max_len)\n",
    "    Y: Class probability, one hot vector (m, # classes)\n",
    "    '''\n",
    "\n",
    "    # Input layer\n",
    "    # X_indices (m, max_len)\n",
    "    X_input = tfl.Input(shape=input_shape, dtype='int32')\n",
    "    \n",
    "    # Embedding layer\n",
    "    embedding_layer = pretrained_embedding_layer(word_to_vector, word_to_index, trainable=trainable)\n",
    "    X = embedding_layer(X_input)   \n",
    "\n",
    "    # Take average\n",
    "    # Get embedding vector dimension\n",
    "    emb_dim = X.shape[2]\n",
    "    # Make a list from slice\n",
    "    X_avg = [ X[:,:,i] for i in range(emb_dim) ]\n",
    "    # Take average of embedding vector\n",
    "    X = tf.keras.layers.Average()(X_avg)\n",
    "\n",
    "\n",
    "    # Masking layer\n",
    "    # skip zero vector words\n",
    "    X = tfl.Masking(mask_value=0.)(X)\n",
    "\n",
    "    # Linear+ReLu layer\n",
    "    X = tfl.Dense(units = 128, activation='relu')(X)\n",
    "    X = tfl.Dropout(rate = 0.4)(X)  \n",
    "\n",
    "    # Linear+ReLu layer\n",
    "    X = tfl.Dense(units = 64, activation='relu')(X)\n",
    "    X = tfl.Dropout(rate = 0.4)(X) \n",
    "\n",
    "    # Linear+ReLu layer\n",
    "    X = tfl.Dense(units = 32, activation='relu')(X)\n",
    "    X = tfl.Dropout(rate = 0.2)(X) \n",
    "\n",
    "    # Linear+Softmax layer\n",
    "    # Output: y (m, # classes), probability of each class\n",
    "    X = tfl.Dense(units = n_class, activation='softmax')(X)\n",
    "\n",
    "    # Model\n",
    "    model = tf.keras.models.Model(inputs=X_input, outputs=X)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaffa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_LSTM(input_shape, word_to_index=False, word_to_vector=False, n_class=2, trainable=False):\n",
    "    '''\n",
    "    input_shape: (max_len,) or (max_len, num_cat)\n",
    "    word_to_index: word to index dictionary, False for one hot encoding\n",
    "    word_to_vector: word to embedding vector dictionary, False for one hot encoding\n",
    "\n",
    "    return model\n",
    "\n",
    "    then\n",
    "    X: Indices of a sentence (m, max_len)\n",
    "    Y: Class probability, one hot vector (m, # classes)\n",
    "    '''\n",
    "\n",
    "    # Input layer\n",
    "    # X_oh (m, max_len, num_cat)\n",
    "    # X_indices (m, max_len)\n",
    "    X_input = tfl.Input(shape=input_shape, dtype='int32')\n",
    "\n",
    "    # Embedding layer\n",
    "    #embedding_layer = pretrained_embedding_layer(word_to_vector, word_to_index, trainable=trainable)\n",
    "    #X = embedding_layer(X_indices)   \n",
    "\n",
    "    # By default, assumes one hot vector input\n",
    "    # If word_to_index, word_to_vector is provided, add an embedding layer\n",
    "    X = X_input\n",
    "    if bool(word_to_index):\n",
    "        # Word embeding\n",
    "        # Output: (m, max_len, emb_dim)\n",
    "        # Embedding layer\n",
    "        embedding_layer = pretrained_embedding_layer(word_to_vector, word_to_index, trainable=trainable)\n",
    "        X = embedding_layer(X)      \n",
    "        # Masking layer\n",
    "        # skip zero vector words\n",
    "        X = tfl.Masking(mask_value=0.)(X)\n",
    "        \n",
    "    else:\n",
    "        X = tf.dtypes.cast(X, tf.float32)\n",
    "\n",
    "    # LSTM layer\n",
    "    # Output: a[1] (m, max_len, 128 hidden unit), batch of sequences\n",
    "    X = tfl.LSTM(units = 128, return_sequences= True)(X)\n",
    "    X = tfl.Dropout(rate = 0.5 )(X) \n",
    "\n",
    "    # LSTM layer\n",
    "    # Output: a[2]<max_len> (m, 128 hidden unit)\n",
    "    X = tfl.LSTM(units = 128)(X)\n",
    "    X = tfl.Dropout(rate = 0.5)(X)  \n",
    "\n",
    "    # Linear layer\n",
    "    # Output: a[3] (m, # classes)\n",
    "    X = tfl.Dense(units = n_class)(X)\n",
    "\n",
    "    # Softmax layer\n",
    "    # Output: y (m, # classes), probability of each class\n",
    "    X = tfl.Activation('softmax')(X)\n",
    "\n",
    "    # Model\n",
    "    model = tf.keras.models.Model(inputs=X_input, outputs=X)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90575f26",
   "metadata": {},
   "source": [
    "# Model wrapper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f950ff84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multiple_NB(model_vars,train,dev,test,Yname='label'):\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for var in model_vars:\n",
    "        \n",
    "        Xname = var\n",
    "        \n",
    "        model_name, y_pred, y_true, proba, classifier, counter = \\\n",
    "            simple_NB(train,dev,test,Xname=Xname,Yname=Yname)\n",
    "        \n",
    "        results.append([model_name, y_pred, y_true, proba, classifier, counter])\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1facd833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multiple_NN(model_vars, train, dev, test, pos_to_index, word_to_index=False, word_to_vector=False, \n",
    "                        Yname='label', max_len=20, n_class=2, \n",
    "                        epochs = 20, batch_size = 32, patience=2, trainable=False):\n",
    "    \n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    _, _, X_train_indices, _,      Y_train_oh = dataframe_to_arrays(train, word_to_index, max_len)\n",
    "    _, _, X_dev_indices,   _,      Y_dev_oh   = dataframe_to_arrays(dev, word_to_index, max_len)\n",
    "    _, _, X_test_indices,  Y_test, _          = dataframe_to_arrays(test, word_to_index, max_len)\n",
    "    \n",
    "    _, _, X_train_indices_pos, _, _ = dataframe_to_arrays(train, pos_to_index, max_len)\n",
    "    _, _, X_dev_indices_pos,   _, _ = dataframe_to_arrays(dev, pos_to_index, max_len)\n",
    "    _, _, X_test_indices_pos,  _, _ = dataframe_to_arrays(test, pos_to_index, max_len)    \n",
    "    \n",
    "\n",
    "    X_emb = [X_train_indices, X_dev_indices, X_test_indices]\n",
    "    X_ohv = [to_categorical(X_train_indices_pos, num_classes=len(pos_to_index)), \n",
    "             to_categorical(X_dev_indices_pos, num_classes=len(pos_to_index)), \n",
    "             to_categorical(X_test_indices_pos, num_classes=len(pos_to_index))]\n",
    "    Y = [Y_train_oh, Y_dev_oh, Y_test]\n",
    "    \n",
    "\n",
    "    \n",
    "    for i in range(len(model_vars)):\n",
    "            \n",
    "        model_name = model_vars[i][0]\n",
    "        func_model = model_vars[i][1]\n",
    "        Xname = model_vars[i][2]\n",
    "        use_embeddings = model_vars[i][3]\n",
    "        \n",
    "        X = X_ohv\n",
    "        w2v = False\n",
    "        w2i = False\n",
    "        X_shape = (max_len, len(pos_to_index))\n",
    "        \n",
    "        if use_embeddings:\n",
    "            X = X_emb\n",
    "            w2i = word_to_index        \n",
    "            w2v = word_to_vector\n",
    "            X_shape = (max_len, )\n",
    "        \n",
    "    \n",
    "        print('should match all: ', X_shape, X[0].shape, X[1].shape, X[2].shape)\n",
    "    \n",
    "        model = func_model(X_shape, w2i, w2v, n_class, trainable)\n",
    "        model.summary()\n",
    "                    \n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=patience)  \n",
    "        \n",
    "        history = False\n",
    "        \n",
    "        if patience :\n",
    "            history = model.fit(X[0], Y[0], \n",
    "                                epochs = epochs, batch_size = batch_size, shuffle=True, \n",
    "                                validation_data=(X[1], Y[1]),\n",
    "                                callbacks=[es])\n",
    "        else:\n",
    "            history = model.fit(X[0], Y[0], \n",
    "                                epochs = epochs, batch_size = batch_size, shuffle=True, \n",
    "                                validation_data=(X[1], Y[1]))\n",
    "            \n",
    "        proba = model.predict(X[2])\n",
    "        y_pred = [np.argmax(proba[i]) for i in range(len(proba))]\n",
    "        y_true = Y[2]\n",
    "        \n",
    "        results.append([model_name, y_pred, y_true, proba, model, history])\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d1d232",
   "metadata": {},
   "source": [
    "# Run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318f5c1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "#simple_NB(train,dev,test,Xname='title',Yname='label') \n",
    "nn_vars = ['cleaned_words','minimal_words','cleaned_pos' ]\n",
    "res_nb =  run_multiple_NB(nn_vars,train,dev,test,Yname='label')\n",
    "    \n",
    "\n",
    "# NN\n",
    "nn_vars = [#['LSTM clean words', model_LSTM, 'cleaned_words', True], \n",
    "              ['LSTM clean pos', model_LSTM, 'cleaned_pos', False],\n",
    "            ['FNN clean words', model_FNN, 'cleaned_words', True]]\n",
    "\n",
    "res_nn = run_multiple_NN(nn_vars, train, dev, test,\n",
    "                         pos_to_index, word_to_index, word_to_vector, \n",
    "                         Yname='label', max_len=max_len, n_class=2,\n",
    "                         epochs = 20, batch_size = 32, patience=2, trainable=False)\n",
    "\n",
    "# Add NB and NN\n",
    "results = res_nb + res_nn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a53745",
   "metadata": {},
   "source": [
    "# Print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70895f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_result(results):\n",
    "    \n",
    "    for result in results:\n",
    "        \n",
    "        model_name, y_pred, y_true, proba = result[:4]\n",
    "        \n",
    "        print(model_name)\n",
    "        print('accuracy: ',accuracy_score(y_true, y_pred))\n",
    "        print('precision: ',precision_score(y_true, y_pred))\n",
    "        print('recall: ',recall_score(y_true, y_pred))\n",
    "        print('f1: ',f1_score(y_true, y_pred))\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cacab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_result(results)\n",
    "\n",
    "#print(len(res_nn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
