{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple naive bayse model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from freq_utils import *\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, precision_score, recall_score, f1_score\n",
    "\n",
    "pd.options.display.max_colwidth = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_csv('data/True.csv')\n",
    "df1 = pd.read_csv('data/Fake.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0['label'] = 0\n",
    "df1['label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_dev_test_split([df0, df1], m=40000, class_column='label', \n",
    "                                        class_balance=True, r_dev=0, r_test=0.2, rand_state=42)\n",
    "\n",
    "\n",
    "train_title = train.title.str.lower().tolist()\n",
    "train_labels = train.label.tolist()\n",
    "\n",
    "test_title = test.title.str.lower().tolist()\n",
    "test_labels = test.label.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = CountVectorizer()\n",
    "\n",
    "counter.fit(train_title+test_title)\n",
    "\n",
    "train_counts = counter.transform(train_title)\n",
    "test_counts = counter.transform(test_title)\n",
    "\n",
    "#print(counter.vocabulary_)\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(train_counts,train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.948125\n",
      "0.9430064708810353\n",
      "0.9532075471698114\n",
      "0.9480795696234205\n"
     ]
    }
   ],
   "source": [
    "predict = classifier.predict(test_counts)\n",
    "\n",
    "print(accuracy_score(test_labels, predict))\n",
    "print(precision_score(test_labels, predict))\n",
    "print(recall_score(test_labels, predict))\n",
    "print(f1_score(test_labels, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "With a simple naive bayse classifier, this model achieved surprisingly high, 95%, accuracy. I would like to explore dataset to see what feature played a key role in classification, whether it was a general feature of fake news or a bias of this specific dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
