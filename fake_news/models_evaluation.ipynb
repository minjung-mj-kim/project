{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe0cc626",
   "metadata": {},
   "source": [
    "# Set constant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115458bc",
   "metadata": {},
   "source": [
    "# Load libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96ecafbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from freq_utils import *\n",
    "\n",
    "import regex as re\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, precision_score, recall_score, f1_score\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from collections import Counter\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "import time\n",
    "import IPython\n",
    "\n",
    "\n",
    "pd.options.display.max_colwidth = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0880d1",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb39b80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_csv('data/TrueOrganized.csv')\n",
    "df1 = pd.read_csv('data/FakeOrganized.csv')\n",
    "df0['label'] = 0\n",
    "df1['label'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9203bc01",
   "metadata": {},
   "source": [
    "# Make dictionaries\n",
    "- Make dictionaries\n",
    "- Get max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0ee40a",
   "metadata": {},
   "source": [
    "### Pretrained word embeddings\n",
    "- Word to index\n",
    "- Word to vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7d68c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index, index_to_word, word_to_vector = get_pretrained_embedding()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092a4814",
   "metadata": {},
   "source": [
    "### PoS tag encodings\n",
    "- PoS word to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6c9f402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 {'dt': 0, 'sym': 1, 'in': 2, 'wp$': 3, 'nn': 4, ',': 5, ')': 6, 'vbg': 7, 'rbr': 8, 'jjs': 9, 'rbs': 10, 'to': 11, 'jj': 12, 'rb': 13, 'vb': 14, 'wp': 15, 'prp': 16, 'fw': 17, ':': 18, 'jjr': 19, 'prp$': 20, 'vbz': 21, 'vbn': 22, 'nns': 23, 'pos': 24, '.': 25, '(': 26, 'wdt': 27, 'nnps': 28, \"''\": 29, 'uh': 30, 'cc': 31, 'cd': 32, 'vbp': 33, 'wrb': 34, 'vbd': 35, 'ex': 36, 'md': 37, 'nnp': 38}\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([df0.cleaned_pos, df1.cleaned_pos])\n",
    "\n",
    "pos_set = set()\n",
    "for x in list(df.str.lower().str.split()):\n",
    "    pos_set.update(x)\n",
    "\n",
    "pos_list = list(pos_set)\n",
    "pos_to_index = { pos_list[i]: i for i in range(len(pos_list)) }\n",
    "\n",
    "print(len(pos_to_index),pos_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d81b4bd",
   "metadata": {},
   "source": [
    "### Get max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a77f598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "org_title \t 20 42\n",
      "lower_title \t 20 42\n",
      "cleaned_words \t 24 49\n",
      "cleaned_pos \t 24 49\n",
      "minimal_words \t 15 35\n",
      "{'org_title': 42, 'lower_title': 42, 'cleaned_words': 49, 'cleaned_pos': 49, 'minimal_words': 35}\n"
     ]
    }
   ],
   "source": [
    "xcol_names = df0.columns[:-1].to_list()\n",
    "input_dict = {}\n",
    "for x in xcol_names:\n",
    "    print(x,'\\t', df0[x].str.split().str.len().max(), df1[x].str.split().str.len().max())\n",
    "    input_dict[x]=df1[x].str.split().str.len().max()\n",
    "print(input_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef43af39",
   "metadata": {},
   "source": [
    "# Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb61b153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_Manual(test):\n",
    "    \n",
    "    y_true = test.label\n",
    "    y_pred = []\n",
    "    \n",
    "    # title size > 20?\n",
    "    y_pred.append( test.apply(lambda row: 1 if len(row['lower_title'].split())> 20 else 0, axis=1) )\n",
    "    # noise > 3 \n",
    "    y_pred.append( test.apply(lambda row: 1 if len(re.findall(re.compile('[^\\s\\w]'), row['lower_title'])) > 5 else 0, axis=1) )\n",
    "    # clickbait, slang, first names\n",
    "    trigger_word = ['_mytag_slang_',\n",
    "                    'donald','obama','hillary','bernie']\n",
    "\n",
    "    for i in range(len(trigger_word)):\n",
    "        y_pred.append( test.minimal_words.str.contains(trigger_word[i])*1 )\n",
    "\n",
    "    cut_name = ['too_long','noisy','slang'] + trigger_word[-4:]\n",
    "\n",
    "    return cut_name, y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "242fa5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_NB(train,dev,test,Xname='title',Yname='label'):\n",
    "    \n",
    "    train = pd.concat([train,dev])\n",
    "    \n",
    "    X_train = train[Xname].tolist()\n",
    "    Y_train = train[Yname].tolist()\n",
    "\n",
    "    X_test = test[Xname].tolist()\n",
    "    Y_test = test[Yname]#.tolist() -> commented out to keep dataframe index\n",
    "    \n",
    "    counter = CountVectorizer()\n",
    "\n",
    "    counter.fit(X_train+X_test)\n",
    "\n",
    "    temp_real = train[train.label==0]\n",
    "    temp_fake = train[train.label==1]\n",
    "    \n",
    "    counter_real = Counter(temp_real[Xname].str.split().explode().tolist())\n",
    "    counter_fake = Counter(temp_fake[Xname].str.split().explode().tolist())\n",
    "\n",
    "    train_counts = counter.transform(X_train)\n",
    "    test_counts = counter.transform(X_test)\n",
    "\n",
    "    #print(counter.vocabulary_)\n",
    "\n",
    "    classifier = MultinomialNB()\n",
    "    classifier.fit(train_counts,Y_train)\n",
    "    \n",
    "    predict = classifier.predict(test_counts)\n",
    "    \n",
    "    proba = classifier.predict_proba(test_counts)\n",
    "    \n",
    "    model_name = 'Naive Bayes - '+Xname\n",
    "    \n",
    "    \n",
    "    return model_name, predict, Y_test, proba, classifier, counter, counter_real, counter_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b48c017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_encoder(X, trainable = True):\n",
    "    \n",
    "    # X input can be either text or PoS vectors\n",
    "    # dim=2 for text -> word index input (m, max_len)\n",
    "    # dim=3 for PoS -> one-hot encoding input (m, max_len, num_cat)\n",
    "    dim = len(X.get_shape().as_list())\n",
    "    \n",
    "    if dim==2:\n",
    "        # Word embedding, indices to vector\n",
    "        # Output: (m, max_len, emb_dim)\n",
    "        X = pretrained_embedding_layer(word_to_vector, word_to_index, trainable=trainable)(X)             \n",
    "    elif dim==3:\n",
    "        # Int to float for One-hot encoding\n",
    "        # Output: (m, max_len, num_cat)\n",
    "        X = tf.dtypes.cast(X, tf.float32)\n",
    "    else:\n",
    "        print('Wrong input shape:', X.get_shape())\n",
    "        \n",
    "    # Skip zero vector words\n",
    "    X = tfl.Masking(mask_value=0.)(X)    \n",
    "    \n",
    "    return X\n",
    "\n",
    "def ml_builder(X, best_hps, ml_type):\n",
    "\n",
    "    # Hyperparameters\n",
    "    drop_out = best_hps.values['drop_out']\n",
    "    \n",
    "    if ml_type=='FNN':\n",
    "        \n",
    "        # Take average of a sentence\n",
    "        max_len = X.shape[1]\n",
    "        X_avg = [ X[:,i,:] for i in range(max_len) ]\n",
    "        X = tf.keras.layers.Average()(X_avg)    \n",
    "        \n",
    "        n_units = [best_hps.values['n_unit1'], best_hps.values['n_unit2'], 16]\n",
    "        \n",
    "        # Linear+ReLu layer\n",
    "        for n_unit in n_units:\n",
    "            X = tfl.Dense(units = n_unit, activation='relu', kernel_initializer='he_normal')(X)\n",
    "            X = tfl.Dropout(rate = drop_out)(X)  \n",
    "            X = tfl.BatchNormalization()(X)\n",
    "    \n",
    "        \n",
    "    elif ml_type=='LSTM':\n",
    "        \n",
    "        n_unit = best_hps.values['n_unit']\n",
    "        re_drop_out = best_hps.values['re_drop_out']\n",
    "        \n",
    "        # Output: a[l] (m, max_len, # hidden unit), batch of sequences\n",
    "        X = tfl.LSTM(units = n_unit, dropout = drop_out, recurrent_dropout=re_drop_out, return_sequences= True)(X)\n",
    "        X = tfl.LSTM(units = n_unit, dropout = drop_out, recurrent_dropout=re_drop_out, return_sequences= True)(X)\n",
    "        # Output: a[l] (m, # hidden unit)\n",
    "        X = tfl.LSTM(units = n_unit, dropout = drop_out, recurrent_dropout=re_drop_out, return_sequences= False)(X)\n",
    "\n",
    "    else:\n",
    "        print('Wrong ml_type:',ml_type)\n",
    "        \n",
    "            \n",
    "    # Linear+Softmax layer\n",
    "    # Output: y (m, # classes=2), probability of each class\n",
    "    X = tfl.Dense(units = 2, activation='softmax')(X)\n",
    "    \n",
    "    return X\n",
    "\n",
    "def ml_optimizer(model, best_hps):\n",
    "    \n",
    "    learning_rate = best_hps.values['learning_rate']\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)                                \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "class DeepModelBuilder():\n",
    "    def __init__(self, input_shape, best_hps, ml_type='LSTM', trainable=True):\n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        self.best_hps = best_hps\n",
    "        self.ml_type = ml_type\n",
    "        self.trainable = trainable\n",
    "    \n",
    "    def build(self):\n",
    "\n",
    "        X_input = tfl.Input(shape=self.input_shape, dtype='int32')\n",
    "\n",
    "        X = input_encoder(X_input, trainable = self.trainable)\n",
    "        X = ml_builder(X, best_hps=self.best_hps, ml_type=self.ml_type)\n",
    "\n",
    "        model = tf.keras.models.Model(inputs=X_input, outputs=X)\n",
    "        model = ml_optimizer(model, best_hps=self.best_hps)\n",
    "\n",
    "        return model\n",
    "    \n",
    "    def fit(self, model, x_train, y_train, x_val, y_val, epochs):\n",
    "        \n",
    "        class ClearTrainingOutput(tf.keras.callbacks.Callback):\n",
    "            def on_train_end(*args, **kwargs):\n",
    "                IPython.display.clear_output(wait = True)\n",
    "        \n",
    "        es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=5)\n",
    "\n",
    "        return model.fit(x_train, y_train,\n",
    "                         validation_data=(x_val, y_val),\n",
    "                         epochs=epochs,\n",
    "                         batch_size=self.best_hps.values['batch_size'], shuffle=True, \n",
    "                         callbacks=[ClearTrainingOutput(), es])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d26a65",
   "metadata": {},
   "source": [
    "# Generate inputs of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2c7bf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes input\n",
    "train, dev, test = train_dev_test_split([df0, df1], m=40000, class_column='label', \n",
    "                                    class_balance=True, r_dev=0.2, r_test=0.05, rand_state=42)\n",
    "# Deep learning model input\n",
    "def make_input(xcol_name, train, dev, test):\n",
    "\n",
    "    max_len = input_dict[xcol_name]\n",
    "    use_embeddings = True\n",
    "    if xcol_name == 'cleaned_pos':\n",
    "        use_embeddings=False\n",
    "\n",
    "    w2i = False\n",
    "    w2v = False\n",
    "    X_shape = False\n",
    "\n",
    "    # Embedding or One-hot encoding\n",
    "    if use_embeddings:\n",
    "        w2i = word_to_index        \n",
    "        w2v = word_to_vector\n",
    "    else:\n",
    "        w2i = pos_to_index\n",
    "\n",
    "    _, _, X_train_indices, _, Y_train_oh = dataframe_to_arrays(train, w2i, max_len, Xname=xcol_name)\n",
    "    _, _, X_dev_indices,   _, Y_dev_oh   = dataframe_to_arrays(dev, w2i, max_len, Xname=xcol_name)\n",
    "    index, _, X_test_indices, Y_test, _  = dataframe_to_arrays(test, w2i, max_len, Xname=xcol_name)\n",
    "\n",
    "    # X, Y (train, dev, test)\n",
    "    X = False\n",
    "    if use_embeddings:\n",
    "        X = [X_train_indices, X_dev_indices, X_test_indices]\n",
    "    else:\n",
    "        X = [to_categorical(X_train_indices, num_classes=len(pos_to_index)), \n",
    "             to_categorical(X_dev_indices, num_classes=len(pos_to_index)), \n",
    "             to_categorical(X_test_indices, num_classes=len(pos_to_index))]            \n",
    "\n",
    "    Y = [Y_train_oh, Y_dev_oh, Y_test]\n",
    "    \n",
    "    print('input column:',xcol_name)\n",
    "    print('max_len:',max_len)\n",
    "    print('use_embeddings?:',use_embeddings)\n",
    "    print('X, Y shapes:', np.shape(X[0]), np.shape(Y[0]))\n",
    "    \n",
    "    # X shape:\n",
    "    # X_oh (m, max_len, num_cat)\n",
    "    # X_indices (m, max_len)\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da92475",
   "metadata": {},
   "source": [
    "# Model wrapper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68c3d4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multiple_NB(model_vars,train,dev,test,Yname='label'):\n",
    "\n",
    "    results = []\n",
    "    imodel = 0\n",
    "    \n",
    "    for var in model_vars:\n",
    "        \n",
    "        Xname = var\n",
    "        \n",
    "        # Bagging\n",
    "        sample_train = pd.concat([train,dev]).sample(frac=0.8/16,replace=True)\n",
    "        sample_dev = pd.concat([train,dev]).sample(frac=0.2/16,replace=True)\n",
    "        \n",
    "        model_name, y_pred, y_true, proba, classifier, counter, counter_real, counter_fake = \\\n",
    "            simple_NB(sample_train,sample_dev,test,Xname=Xname,Yname=Yname)\n",
    "        \n",
    "        x = test[Xname].to_numpy()\n",
    "        \n",
    "        model_name = model_name+' '+Xname\n",
    "        \n",
    "        save_name = 'data/nb'+str(imodel)\n",
    "        dump(classifier,save_name)\n",
    "        save_name = 'data/nb_counter'+str(imodel)\n",
    "        dump(counter,save_name)\n",
    "        save_name = 'data/nb_counter_real'+str(imodel)\n",
    "        dump(counter_real,save_name)\n",
    "        save_name = 'data/nb_counter_fake'+str(imodel)\n",
    "        dump(counter_fake,save_name)\n",
    "        \n",
    "        results.append([model_name, x, y_pred, y_true, proba, classifier, counter, counter_real, counter_fake])\n",
    "        \n",
    "        imodel+=1\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf4183d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multiple_NN(trainable=True):\n",
    "       \n",
    "    durations=[]\n",
    "    results = []\n",
    "    imodel = 0\n",
    "\n",
    "    for ml_type in ('LSTM','FNN'):\n",
    "        for xcol_name in xcol_names:\n",
    "\n",
    "            #if not (ml_type=='FNN' and xcol_name=='cleaned_pos'):\n",
    "            #    continue\n",
    "\n",
    "            begin_time = time.time()\n",
    "            \n",
    "            sample_train = pd.concat([train,dev]).sample(frac=0.8/16,replace=True)\n",
    "            sample_dev = pd.concat([train,dev]).sample(frac=0.2/16,replace=True)\n",
    "\n",
    "            X, Y  = make_input(xcol_name, sample_train, sample_dev, test)\n",
    "            \n",
    "            dir_name = ml_type+'_'+xcol_name\n",
    "\n",
    "            # Get hyperparameter dictionary       \n",
    "            save_name = 'data/'+dir_name+'_best_hps'\n",
    "            best_hps=load(save_name)\n",
    "            save_name = 'data/'+dir_name+'_best_hps_reg'\n",
    "            best_hps_reg=load(save_name)\n",
    "            best_hps.values.update(best_hps_reg.values)\n",
    "\n",
    "            # Build a model and train\n",
    "            mb = DeepModelBuilder(X[0][0].shape, best_hps, ml_type=ml_type, trainable=trainable)\n",
    "            model = mb.build()\n",
    "            history = mb.fit(model, X[0], Y[0], X[1], Y[1], epochs=100)\n",
    "\n",
    "            # Test\n",
    "            proba = model.predict(X[2])\n",
    "            y_pred = [np.argmax(proba[i]) for i in range(len(proba))]\n",
    "            y_true = Y[2]\n",
    "            x = X[2]\n",
    "\n",
    "            #save_name = 'data/nn'+str(i)\n",
    "            #model.save(save_name)\n",
    "            save_name = 'data/nn_history'+str(imodel)\n",
    "            dump(history,save_name)\n",
    "\n",
    "            results.append([dir_name, x, y_pred, y_true, proba, model, history])\n",
    "            \n",
    "            imodel+=1\n",
    "            \n",
    "            end_time = time.time()\n",
    "            durations.append([ml_type,xcol_name,(end_time-begin_time)/60,'min.'])\n",
    "\n",
    "    return results, durations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04f5d05",
   "metadata": {},
   "source": [
    "# Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97f61b7a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://b4a0db06-f7d3-400c-ac9a-ae9db63d54f3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://b4a0db06-f7d3-400c-ac9a-ae9db63d54f3/assets\n",
      "/Users/minjungkim/opt/anaconda3/lib/python3.8/site-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "/Users/minjungkim/opt/anaconda3/lib/python3.8/site-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.73258802890778 [['LSTM', 'org_title', 4.368123201529185, 'min.'], ['LSTM', 'lower_title', 5.010114284356435, 'min.'], ['LSTM', 'cleaned_words', 4.52064251502355, 'min.'], ['LSTM', 'cleaned_pos', 11.574068331718445, 'min.'], ['LSTM', 'minimal_words', 4.818503717581431, 'min.'], ['FNN', 'org_title', 1.1048944354057313, 'min.'], ['FNN', 'lower_title', 2.127064367135366, 'min.'], ['FNN', 'cleaned_words', 2.529555829366048, 'min.'], ['FNN', 'cleaned_pos', 0.15000534852345784, 'min.'], ['FNN', 'minimal_words', 2.5296159982681274, 'min.']]\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "res_nb =  run_multiple_NB(xcol_names,train,dev,test,Yname='label')\n",
    "    \n",
    "# Neural Networks\n",
    "res_deep, durations = run_multiple_NN(trainable=True)\n",
    "    \n",
    "# Add NB and NN\n",
    "results = res_nb + res_deep\n",
    "\n",
    "print(np.array([x[2] for x in durations]).sum(), durations) # 5 min. for 1000/16, 40 min. for 40000/16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0a6775",
   "metadata": {},
   "source": [
    "# Print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c778af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes - org_title org_title\n",
      "accuracy:  0.9255\n",
      "precision:  0.9140096618357488\n",
      "recall:  0.9403578528827038\n",
      "f1:  0.9269965703086723\n",
      "\n",
      "\n",
      "Naive Bayes - lower_title lower_title\n",
      "accuracy:  0.922\n",
      "precision:  0.9032258064516129\n",
      "recall:  0.9463220675944334\n",
      "f1:  0.9242718446601942\n",
      "\n",
      "\n",
      "Naive Bayes - cleaned_words cleaned_words\n",
      "accuracy:  0.9305\n",
      "precision:  0.9270935960591133\n",
      "recall:  0.9353876739562624\n",
      "f1:  0.9312221672439387\n",
      "\n",
      "\n",
      "Naive Bayes - cleaned_pos cleaned_pos\n",
      "accuracy:  0.807\n",
      "precision:  0.8003875968992248\n",
      "recall:  0.8210735586481114\n",
      "f1:  0.8105986261040236\n",
      "\n",
      "\n",
      "Naive Bayes - minimal_words minimal_words\n",
      "accuracy:  0.9035\n",
      "precision:  0.9118541033434651\n",
      "recall:  0.8946322067594433\n",
      "f1:  0.9031610637230307\n",
      "\n",
      "\n",
      "LSTM_org_title\n",
      "accuracy:  0.9065\n",
      "precision:  0.9261186264308012\n",
      "recall:  0.8846918489065606\n",
      "f1:  0.9049313675648195\n",
      "\n",
      "\n",
      "LSTM_lower_title\n",
      "accuracy:  0.8635\n",
      "precision:  0.7977254264825345\n",
      "recall:  0.9761431411530815\n",
      "f1:  0.8779615556548949\n",
      "\n",
      "\n",
      "LSTM_cleaned_words\n",
      "accuracy:  0.934\n",
      "precision:  0.9441056910569106\n",
      "recall:  0.9234592445328031\n",
      "f1:  0.9336683417085426\n",
      "\n",
      "\n",
      "LSTM_cleaned_pos\n",
      "accuracy:  0.8855\n",
      "precision:  0.9379932356257046\n",
      "recall:  0.827037773359841\n",
      "f1:  0.8790279978869519\n",
      "\n",
      "\n",
      "LSTM_minimal_words\n",
      "accuracy:  0.911\n",
      "precision:  0.8920454545454546\n",
      "recall:  0.9363817097415507\n",
      "f1:  0.9136760426770126\n",
      "\n",
      "\n",
      "FNN_org_title\n",
      "accuracy:  0.8895\n",
      "precision:  0.8433945756780402\n",
      "recall:  0.9582504970178927\n",
      "f1:  0.8971614704513726\n",
      "\n",
      "\n",
      "FNN_lower_title\n",
      "accuracy:  0.8855\n",
      "precision:  0.9093782929399368\n",
      "recall:  0.8578528827037774\n",
      "f1:  0.8828644501278773\n",
      "\n",
      "\n",
      "FNN_cleaned_words\n",
      "accuracy:  0.913\n",
      "precision:  0.9803695150115473\n",
      "recall:  0.8439363817097415\n",
      "f1:  0.907051282051282\n",
      "\n",
      "\n",
      "FNN_cleaned_pos\n",
      "accuracy:  0.8125\n",
      "precision:  0.9787556904400607\n",
      "recall:  0.6411530815109344\n",
      "f1:  0.7747747747747747\n",
      "\n",
      "\n",
      "FNN_minimal_words\n",
      "accuracy:  0.8925\n",
      "precision:  0.9409141583054627\n",
      "recall:  0.8389662027833003\n",
      "f1:  0.8870204939569103\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_result(results):\n",
    "    \n",
    "    for result in results:\n",
    "        \n",
    "        model_name, x, y_pred, y_true, proba = result[:5]\n",
    "        \n",
    "        y_true = y_true.to_numpy()\n",
    "        \n",
    "        print(model_name)\n",
    "        print('accuracy: ',accuracy_score(y_true, y_pred))\n",
    "        print('precision: ',precision_score(y_true, y_pred))\n",
    "        print('recall: ',recall_score(y_true, y_pred))\n",
    "        print('f1: ',f1_score(y_true, y_pred))\n",
    "        print('\\n')\n",
    "print_result(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a15732",
   "metadata": {},
   "source": [
    "# Organize results into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0f1a88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = []\n",
    "\n",
    "for i in range(len(results)):\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'x': results[i][1].tolist(),\n",
    "        'y_true': results[i][3].to_numpy().tolist(),\n",
    "        'y_pred': results[i][2],\n",
    "        'proba0': [results[i][4][j][0] for j in range(len(results[i][1])) ],\n",
    "        'proba1': [results[i][4][j][1] for j in range(len(results[i][1])) ]\n",
    "    }, index = results[i][3].index)\n",
    "    df_result.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6752db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_type = ['Original','Lower','CleanedWords','PoS','MinimalWords']\n",
    "ml_type = ['NaiveBayes','FNN','LSTM']\n",
    "seq_type_abb = ['og','lo','cw','ps','mw']\n",
    "ml_type_abb = ['nb','fnn','lstm']\n",
    "\n",
    "n_ml = len(ml_type)\n",
    "n_seq = len(seq_type)\n",
    "\n",
    "title_vars = ['org_title','lower_title','cleaned_words','cleaned_pos','minimal_words']\n",
    "\n",
    "dict_name = []\n",
    "\n",
    "for i in range(n_ml):\n",
    "    for j in range(n_seq):\n",
    "        \n",
    "        y_pred = ml_type_abb[i]+'_'+seq_type_abb[j]\n",
    "        proba0 = y_pred+'_p0'\n",
    "        proba1 = y_pred+'_p1'\n",
    "        temp_dict = {'y_pred':y_pred,'proba0':proba0,'proba1':proba1}\n",
    "        \n",
    "        if i==0:\n",
    "            x = title_vars[j]\n",
    "            temp_dict['x'] = x\n",
    "        \n",
    "        dict_name.append(temp_dict)\n",
    "\n",
    "df = []\n",
    "\n",
    "\n",
    "df.append(df_result[0].rename(columns = dict_name[0]))\n",
    "for i in range(1,n_seq):\n",
    "    df.append(df_result[i].drop(['y_true'], axis=1, inplace=False).rename(columns = dict_name[i]))\n",
    "\n",
    "for i in range(n_seq, n_ml*n_seq):\n",
    "    df.append(df_result[i].drop(['x','y_true'], axis=1, inplace=False).rename(columns = dict_name[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a2b4586",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y 2000\n"
     ]
    }
   ],
   "source": [
    "df_x = df[0][title_vars[0]].to_frame()\n",
    "for i in range(1,n_seq):\n",
    "    df_x = pd.merge(df_x, df[i][title_vars[i]].to_frame(), left_index=True, right_index=True)\n",
    "    #print(i,len(df_x))\n",
    "\n",
    "df_y = df[0].y_true.to_frame() \n",
    "print('y',len(df_y))\n",
    "    \n",
    "df[0].drop(['y_true'], axis=1, inplace=True)\n",
    "for i in range(0,n_seq):\n",
    "    df[i].drop([title_vars[i]], axis=1, inplace=True)\n",
    "\n",
    "df_p = df[0]    \n",
    "for i in range(1,n_seq*n_ml):\n",
    "    df_p = pd.merge(df_p,df[i], left_index=True, right_index=True)\n",
    "    \n",
    "df_ml = pd.merge(df_x, df_y, left_index=True, right_index=True)\n",
    "df_ml = pd.merge(df_ml, df_p, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d17d0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_name, y_true_cut, y_pred_cut = simple_Manual(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e1059e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_manual = {cut_name[i]:y_pred_cut[i] for i in range(len(cut_name))}\n",
    "\n",
    "df_manual = pd.DataFrame(dict_manual)\n",
    "\n",
    "#display(df_manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d97e10a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.merge(df_ml, df_manual, left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b22add74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>org_title</th>\n",
       "      <th>lower_title</th>\n",
       "      <th>cleaned_words</th>\n",
       "      <th>cleaned_pos</th>\n",
       "      <th>minimal_words</th>\n",
       "      <th>y_true</th>\n",
       "      <th>nb_og</th>\n",
       "      <th>nb_og_p0</th>\n",
       "      <th>nb_og_p1</th>\n",
       "      <th>nb_lo</th>\n",
       "      <th>...</th>\n",
       "      <th>lstm_mw</th>\n",
       "      <th>lstm_mw_p0</th>\n",
       "      <th>lstm_mw_p1</th>\n",
       "      <th>too_long</th>\n",
       "      <th>noisy</th>\n",
       "      <th>slang</th>\n",
       "      <th>donald</th>\n",
       "      <th>obama</th>\n",
       "      <th>hillary</th>\n",
       "      <th>bernie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23128</th>\n",
       "      <td>MARINE ARRESTED FOR Complaining About Government On Facebook Is Suing Government [VIDEO]</td>\n",
       "      <td>marine arrested for complaining about government on facebook is suing government [video]</td>\n",
       "      <td>marine arrested for complaining about government on facebook is suing government [ video ]</td>\n",
       "      <td>NNP NN IN VBG IN NN IN NN NN VBG NN NN NN NN</td>\n",
       "      <td>marine arrested complain government facebook sue government video</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000940</td>\n",
       "      <td>0.999060</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.999300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39728</th>\n",
       "      <td>MUSLIM MEN WIN BIG DISCRIMINATION SUIT Against Employer For Violating Religious Beliefs, While Nuns, Christian Bakers And City Clerks All Lose Cases</td>\n",
       "      <td>muslim men win big discrimination suit against employer for violating religious beliefs, while nuns, christian bakers and city clerks all lose cases</td>\n",
       "      <td>muslim men win big discrimination suit against employer for violating religious beliefs , while nuns , christian bakers and city clerks all lose cases</td>\n",
       "      <td>NN NN VB NN NN NN IN NN IN VBG JJ NNS , IN NNS , JJ NNS CC NNP NNS DT VB NNS</td>\n",
       "      <td>muslim men win big discrimination suit employer violate religious belief nun christian baker city clerk lose case</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.999780</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7651</th>\n",
       "      <td>Republican U.S. Senator Cochran postpones return to Washington</td>\n",
       "      <td>republican u.s. senator cochran postpones return to washington</td>\n",
       "      <td>republican  _u_s_  senator cochran postpones return to washington</td>\n",
       "      <td>JJ NNP NN NN NNS NN TO NNP</td>\n",
       "      <td>republican _u_s_ senator cochran postpones return washington</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.993132</td>\n",
       "      <td>0.006868</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33950</th>\n",
       "      <td>POLICE UNION Threatens 49er’s With BOYCOTT: TAKE ACTION Against Bench-Warmer Kaepernick’s “Inappropriate Behavior” Or We May Choose To “Not Work At Your Facilities”</td>\n",
       "      <td>police union threatens 49er’s with boycott: take action against bench-warmer kaepernick’s “inappropriate behavior” or we may choose to “not work at your facilities”</td>\n",
       "      <td>police union threatens _digit_ er’s with boycott : take action against bench _ warmer kaepernick’s “inappropriate behavior” or we may choose to “not work at your facilities”</td>\n",
       "      <td>NNS NN NNS NN NN IN NN : VB NN IN NN NN NN NNP NN NN CC PRP NNP VB TO NN NN IN PRP$ NN</td>\n",
       "      <td>police union threatens _digit_ boycott take action bench warmer kaepernick inappropriate behavior may choose work facility</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.229152</td>\n",
       "      <td>0.770848</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.975039</td>\n",
       "      <td>0.024961</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20197</th>\n",
       "      <td>Trump HUMILIATED As WH Walks Back His Attack After Soldier’s Mom Confirms His Insensitive Phone Call</td>\n",
       "      <td>trump humiliated as wh walks back his attack after soldier’s mom confirms his insensitive phone call</td>\n",
       "      <td>trump humiliated as wh walks back his attack after soldier’s mom confirms his insensitive phone call</td>\n",
       "      <td>NN NN IN NN NNS RB PRP$ NN IN NN NN NNS PRP$ JJ NN VB</td>\n",
       "      <td>trump humiliated walk back attack soldier mom confirms insensitive phone call</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001816</td>\n",
       "      <td>0.998184</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001822</td>\n",
       "      <td>0.998178</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4852</th>\n",
       "      <td>Congress should consider help for Puerto Rico's disabled: Task force</td>\n",
       "      <td>congress should consider help for puerto rico's disabled: task force</td>\n",
       "      <td>congress should consider help for puerto rico 's disabled : task force</td>\n",
       "      <td>NNP MD VB NN IN NN NNP POS JJ : NN NN</td>\n",
       "      <td>congress consider help puerto rico disabled task force</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997361</td>\n",
       "      <td>0.002639</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.422287</td>\n",
       "      <td>0.577713</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27112</th>\n",
       "      <td>CLINTON MEGA-CHARITY: “Slush Fund For The Clinton’s” Took In $140 Million… Gave Pittance In Direct Aid</td>\n",
       "      <td>clinton mega-charity: “slush fund for the clinton’s” took in $140 million… gave pittance in direct aid</td>\n",
       "      <td>clinton mega _ charity : “slush fund for the clinton’s” took in _digit_ million… gave pittance in direct aid</td>\n",
       "      <td>NN NN NN NN : NN NN IN DT NN NN IN NN NN VB NN IN JJ NN</td>\n",
       "      <td>clinton mega charity slush fund clinton took _digit_ million give pittance direct aid</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.063773</td>\n",
       "      <td>0.936227</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.965185</td>\n",
       "      <td>0.034815</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15154</th>\n",
       "      <td>Trump denounces attack in London, urges 'proactive' steps</td>\n",
       "      <td>trump denounces attack in london, urges 'proactive' steps</td>\n",
       "      <td>trump denounces attack in london , urges 'proactive ' steps</td>\n",
       "      <td>NN NNS NN IN NNP , NNS JJ '' NNS</td>\n",
       "      <td>trump denounces attack london urge proactive step</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999822</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998154</td>\n",
       "      <td>0.001846</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25290</th>\n",
       "      <td>Democrat Spills The Beans On Why Hispanics Love Obamacare So Much [Video]</td>\n",
       "      <td>democrat spills the beans on why hispanics love obamacare so much [video]</td>\n",
       "      <td>democrat spills the beans on why hispanics love obamacare so much [ video ]</td>\n",
       "      <td>NNP NNS DT NNS IN WRB NNS VB NN RB JJ NN NN NN</td>\n",
       "      <td>democrat spill bean hispanic love obamacare much video</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001726</td>\n",
       "      <td>0.998274</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15696</th>\n",
       "      <td>Trump says he's sure Senator Paul will back Republican health plan</td>\n",
       "      <td>trump says he's sure senator paul will back republican health plan</td>\n",
       "      <td>trump says he 's sure senator paul will back republican health plan</td>\n",
       "      <td>NN VBZ PRP POS NN NN NNP MD RB JJ NN NN</td>\n",
       "      <td>trump say sure senator paul back republican health plan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.645853</td>\n",
       "      <td>0.354147</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998833</td>\n",
       "      <td>0.001168</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                  org_title  \\\n",
       "23128                                                                              MARINE ARRESTED FOR Complaining About Government On Facebook Is Suing Government [VIDEO]   \n",
       "39728                  MUSLIM MEN WIN BIG DISCRIMINATION SUIT Against Employer For Violating Religious Beliefs, While Nuns, Christian Bakers And City Clerks All Lose Cases   \n",
       "7651                                                                                                         Republican U.S. Senator Cochran postpones return to Washington   \n",
       "33950  POLICE UNION Threatens 49er’s With BOYCOTT: TAKE ACTION Against Bench-Warmer Kaepernick’s “Inappropriate Behavior” Or We May Choose To “Not Work At Your Facilities”   \n",
       "20197                                                                  Trump HUMILIATED As WH Walks Back His Attack After Soldier’s Mom Confirms His Insensitive Phone Call   \n",
       "4852                                                                                                   Congress should consider help for Puerto Rico's disabled: Task force   \n",
       "27112                                                                CLINTON MEGA-CHARITY: “Slush Fund For The Clinton’s” Took In $140 Million… Gave Pittance In Direct Aid   \n",
       "15154                                                                                                             Trump denounces attack in London, urges 'proactive' steps   \n",
       "25290                                                                                             Democrat Spills The Beans On Why Hispanics Love Obamacare So Much [Video]   \n",
       "15696                                                                                                    Trump says he's sure Senator Paul will back Republican health plan   \n",
       "\n",
       "                                                                                                                                                                lower_title  \\\n",
       "23128                                                                              marine arrested for complaining about government on facebook is suing government [video]   \n",
       "39728                  muslim men win big discrimination suit against employer for violating religious beliefs, while nuns, christian bakers and city clerks all lose cases   \n",
       "7651                                                                                                         republican u.s. senator cochran postpones return to washington   \n",
       "33950  police union threatens 49er’s with boycott: take action against bench-warmer kaepernick’s “inappropriate behavior” or we may choose to “not work at your facilities”   \n",
       "20197                                                                  trump humiliated as wh walks back his attack after soldier’s mom confirms his insensitive phone call   \n",
       "4852                                                                                                   congress should consider help for puerto rico's disabled: task force   \n",
       "27112                                                                clinton mega-charity: “slush fund for the clinton’s” took in $140 million… gave pittance in direct aid   \n",
       "15154                                                                                                             trump denounces attack in london, urges 'proactive' steps   \n",
       "25290                                                                                             democrat spills the beans on why hispanics love obamacare so much [video]   \n",
       "15696                                                                                                    trump says he's sure senator paul will back republican health plan   \n",
       "\n",
       "                                                                                                                                                                       cleaned_words  \\\n",
       "23128                                                                                     marine arrested for complaining about government on facebook is suing government [ video ]   \n",
       "39728                         muslim men win big discrimination suit against employer for violating religious beliefs , while nuns , christian bakers and city clerks all lose cases   \n",
       "7651                                                                                                               republican  _u_s_  senator cochran postpones return to washington   \n",
       "33950  police union threatens _digit_ er’s with boycott : take action against bench _ warmer kaepernick’s “inappropriate behavior” or we may choose to “not work at your facilities”   \n",
       "20197                                                                           trump humiliated as wh walks back his attack after soldier’s mom confirms his insensitive phone call   \n",
       "4852                                                                                                          congress should consider help for puerto rico 's disabled : task force   \n",
       "27112                                                                   clinton mega _ charity : “slush fund for the clinton’s” took in _digit_ million… gave pittance in direct aid   \n",
       "15154                                                                                                                    trump denounces attack in london , urges 'proactive ' steps   \n",
       "25290                                                                                                    democrat spills the beans on why hispanics love obamacare so much [ video ]   \n",
       "15696                                                                                                            trump says he 's sure senator paul will back republican health plan   \n",
       "\n",
       "                                                                                  cleaned_pos  \\\n",
       "23128                                            NNP NN IN VBG IN NN IN NN NN VBG NN NN NN NN   \n",
       "39728            NN NN VB NN NN NN IN NN IN VBG JJ NNS , IN NNS , JJ NNS CC NNP NNS DT VB NNS   \n",
       "7651                                                               JJ NNP NN NN NNS NN TO NNP   \n",
       "33950  NNS NN NNS NN NN IN NN : VB NN IN NN NN NN NNP NN NN CC PRP NNP VB TO NN NN IN PRP$ NN   \n",
       "20197                                   NN NN IN NN NNS RB PRP$ NN IN NN NN NNS PRP$ JJ NN VB   \n",
       "4852                                                    NNP MD VB NN IN NN NNP POS JJ : NN NN   \n",
       "27112                                 NN NN NN NN : NN NN IN DT NN NN IN NN NN VB NN IN JJ NN   \n",
       "15154                                                        NN NNS NN IN NNP , NNS JJ '' NNS   \n",
       "25290                                          NNP NNS DT NNS IN WRB NNS VB NN RB JJ NN NN NN   \n",
       "15696                                                 NN VBZ PRP POS NN NN NNP MD RB JJ NN NN   \n",
       "\n",
       "                                                                                                                    minimal_words  \\\n",
       "23128                                                           marine arrested complain government facebook sue government video   \n",
       "39728           muslim men win big discrimination suit employer violate religious belief nun christian baker city clerk lose case   \n",
       "7651                                                                 republican _u_s_ senator cochran postpones return washington   \n",
       "33950  police union threatens _digit_ boycott take action bench warmer kaepernick inappropriate behavior may choose work facility   \n",
       "20197                                               trump humiliated walk back attack soldier mom confirms insensitive phone call   \n",
       "4852                                                                       congress consider help puerto rico disabled task force   \n",
       "27112                                       clinton mega charity slush fund clinton took _digit_ million give pittance direct aid   \n",
       "15154                                                                           trump denounces attack london urge proactive step   \n",
       "25290                                                                      democrat spill bean hispanic love obamacare much video   \n",
       "15696                                                                     trump say sure senator paul back republican health plan   \n",
       "\n",
       "       y_true  nb_og  nb_og_p0  nb_og_p1  nb_lo  ...  lstm_mw  lstm_mw_p0  \\\n",
       "23128       1      1  0.000940  0.999060      1  ...        1    0.000700   \n",
       "39728       1      1  0.000004  0.999996      1  ...        1    0.000220   \n",
       "7651        0      0  0.993132  0.006868      0  ...        0    0.999999   \n",
       "33950       1      1  0.229152  0.770848      1  ...        0    0.975039   \n",
       "20197       1      1  0.001816  0.998184      1  ...        1    0.001822   \n",
       "4852        0      0  0.997361  0.002639      0  ...        1    0.422287   \n",
       "27112       1      1  0.063773  0.936227      1  ...        0    0.965185   \n",
       "15154       0      0  0.999822  0.000178      0  ...        0    0.998154   \n",
       "25290       1      1  0.000001  0.999999      1  ...        1    0.001726   \n",
       "15696       0      0  0.645853  0.354147      1  ...        0    0.998833   \n",
       "\n",
       "       lstm_mw_p1  too_long  noisy  slang  donald  obama  hillary  bernie  \n",
       "23128    0.999300         0      0      0       0      0        0       0  \n",
       "39728    0.999780         1      0      0       0      0        0       0  \n",
       "7651     0.000001         0      0      0       0      0        0       0  \n",
       "33950    0.024961         1      1      0       0      0        0       0  \n",
       "20197    0.998178         0      0      0       0      0        0       0  \n",
       "4852     0.577713         0      0      0       0      0        0       0  \n",
       "27112    0.034815         0      1      0       0      0        0       0  \n",
       "15154    0.001846         0      0      0       0      0        0       0  \n",
       "25290    0.998274         0      0      0       0      1        0       0  \n",
       "15696    0.001168         0      0      0       0      0        0       0  \n",
       "\n",
       "[10 rows x 58 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['org_title', 'lower_title', 'cleaned_words', 'cleaned_pos',\n",
      "       'minimal_words', 'y_true', 'nb_og', 'nb_og_p0', 'nb_og_p1', 'nb_lo',\n",
      "       'nb_lo_p0', 'nb_lo_p1', 'nb_cw', 'nb_cw_p0', 'nb_cw_p1', 'nb_ps',\n",
      "       'nb_ps_p0', 'nb_ps_p1', 'nb_mw', 'nb_mw_p0', 'nb_mw_p1', 'fnn_og',\n",
      "       'fnn_og_p0', 'fnn_og_p1', 'fnn_lo', 'fnn_lo_p0', 'fnn_lo_p1', 'fnn_cw',\n",
      "       'fnn_cw_p0', 'fnn_cw_p1', 'fnn_ps', 'fnn_ps_p0', 'fnn_ps_p1', 'fnn_mw',\n",
      "       'fnn_mw_p0', 'fnn_mw_p1', 'lstm_og', 'lstm_og_p0', 'lstm_og_p1',\n",
      "       'lstm_lo', 'lstm_lo_p0', 'lstm_lo_p1', 'lstm_cw', 'lstm_cw_p0',\n",
      "       'lstm_cw_p1', 'lstm_ps', 'lstm_ps_p0', 'lstm_ps_p1', 'lstm_mw',\n",
      "       'lstm_mw_p0', 'lstm_mw_p1', 'too_long', 'noisy', 'slang', 'donald',\n",
      "       'obama', 'hillary', 'bernie'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "display(df_final.sample(10))\n",
    "\n",
    "print(df_final.columns)\n",
    "\n",
    "df_final.to_csv('data/model_compare4.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
